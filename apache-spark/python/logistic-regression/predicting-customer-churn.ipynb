{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('churn-classifier').master('local[4]').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('../data/customer_churn.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos:  150 neg:  750\n"
     ]
    }
   ],
   "source": [
    "# data set is imbalanced!\n",
    "pos_cnt = df.filter(df['Churn'] == 1).count()\n",
    "neg_cnt = df.filter(df['Churn'] == 0).count()\n",
    "print('pos: ', pos_cnt, 'neg: ', neg_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names: Cameron Williams\n",
      "Age: 42.0\n",
      "Total_Purchase: 11066.8\n",
      "Account_Manager: 0\n",
      "Years: 7.22\n",
      "Num_Sites: 8.0\n",
      "Onboard_date: 2013-08-30 07:00:40\n",
      "Location: 10265 Elizabeth Mission Barkerburgh, AK 89518\n",
      "Company: Harvey LLC\n",
      "Churn: 1\n"
     ]
    }
   ],
   "source": [
    "for col, item in zip(df.columns, df.take(1)[0]):\n",
    "    print(col + ': ' + str(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = df.select('Age', 'Total_Purchase', 'Years', 'Num_Sites', 'Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_na = my_cols.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_na.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no missing data was removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (VectorAssembler, VectorIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Age', 'Total_Purchase', 'Years', 'Num_Sites'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = assembler.transform(my_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(featuresCol='features', labelCol='Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_log_reg = log_reg.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol='Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = fit_log_reg.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+-----+---------+-----+--------------------+--------------------+--------------------+----------+\n",
      "| Age|Total_Purchase|Years|Num_Sites|Churn|            features|       rawPrediction|         probability|prediction|\n",
      "+----+--------------+-----+---------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|22.0|      11254.38| 4.96|      8.0|    0|[22.0,11254.38,4....|[4.75267893569920...|[0.99144526605447...|       0.0|\n",
      "|25.0|       9672.03| 5.49|      8.0|    0|[25.0,9672.03,5.4...|[4.30748677406267...|[0.98671160590182...|       0.0|\n",
      "|28.0|      11128.95| 5.12|      8.0|    0|[28.0,11128.95,5....|[4.37006516427899...|[0.98750761764998...|       0.0|\n",
      "|28.0|      11245.38| 6.72|      8.0|    0|[28.0,11245.38,6....|[3.44424048595928...|[0.96905891465598...|       0.0|\n",
      "|29.0|       5900.78| 5.56|      8.0|    0|[29.0,5900.78,5.5...|[4.08906402590924...|[0.98352119252748...|       0.0|\n",
      "|29.0|      13255.05| 4.89|      8.0|    0|[29.0,13255.05,4....|[4.44574188039318...|[0.98840755907295...|       0.0|\n",
      "|30.0|       6744.87| 5.14|      9.0|    0|[30.0,6744.87,5.1...|[2.99093649550137...|[0.95216298430962...|       0.0|\n",
      "|30.0|       8677.28| 7.31|      7.0|    0|[30.0,8677.28,7.3...|[4.30597008224511...|[0.98669170463568...|       0.0|\n",
      "|30.0|       8874.83| 5.56|      9.0|    0|[30.0,8874.83,5.5...|[2.73911315491680...|[0.93929554898755...|       0.0|\n",
      "|30.0|      10183.98| 5.14|      9.0|    0|[30.0,10183.98,5....|[2.97653008341981...|[0.95150250089890...|       0.0|\n",
      "|30.0|      10744.14| 7.16|      9.0|    1|[30.0,10744.14,7....|[1.80594567232228...|[0.85887115781405...|       0.0|\n",
      "|30.0|      11575.37| 5.22|      8.0|    1|[30.0,11575.37,5....|[4.21349305331673...|[0.98542108949431...|       0.0|\n",
      "|31.0|       8688.21| 3.58|      7.0|    0|[31.0,8688.21,3.5...|[6.41468181962372...|[0.99836533570755...|       0.0|\n",
      "|31.0|       10182.6| 3.77|      8.0|    0|[31.0,10182.6,3.7...|[5.00947972290456...|[0.99336987699924...|       0.0|\n",
      "|32.0|       5756.12|  5.9|      8.0|    0|[32.0,5756.12,5.9...|[3.74773315235553...|[0.97697168563058...|       0.0|\n",
      "|32.0|       9885.12| 6.92|      9.0|    1|[32.0,9885.12,6.9...|[1.85147614470381...|[0.86430032614557...|       0.0|\n",
      "|32.0|      12142.99| 5.01|      7.0|    0|[32.0,12142.99,5....|[5.52475561335084...|[0.99602898889319...|       0.0|\n",
      "|32.0|      13630.93| 4.38|     10.0|    0|[32.0,13630.93,4....|[2.01569903978633...|[0.88243554778537...|       0.0|\n",
      "|33.0|      10306.21| 6.36|      9.0|    0|[33.0,10306.21,6....|[2.12514588464125...|[0.89332330918783...|       0.0|\n",
      "|33.0|      10709.39| 5.22|      6.0|    0|[33.0,10709.39,5....|[6.64993457241252...|[0.99870756577490...|       0.0|\n",
      "+----+--------------+-----+---------+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluator.evaluate(pred_labels.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8984906462585042"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr_model = log_reg.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_customers = spark.read.csv('../data/new_customers.csv',inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_customers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_customers_df = assembler.transform(new_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Names='Andrew Mccall', Age=37.0, Total_Purchase=9935.53, Account_Manager=1, Years=7.71, Num_Sites=8.0, Onboard_date=datetime.datetime(2011, 8, 29, 18, 37, 54), Location='38612 Johnny Stravenue Nataliebury, WI 15717-8316', Company='King Ltd', features=DenseVector([37.0, 9935.53, 7.71, 8.0]))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_customers_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = final_lr_model.transform(new_customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+----------+--------------------+\n",
      "|         Names| Age|prediction|         probability|\n",
      "+--------------+----+----------+--------------------+\n",
      "| Andrew Mccall|37.0|       0.0|[0.91821394450559...|\n",
      "|Michele Wright|23.0|       1.0|[0.00249574827398...|\n",
      "|  Jeremy Chang|65.0|       1.0|[0.03129415226295...|\n",
      "|Megan Ferguson|32.0|       1.0|[0.00475889563977...|\n",
      "|  Taylor Young|32.0|       0.0|[0.78319303188952...|\n",
      "| Jessica Drake|22.0|       1.0|[0.19177446955641...|\n",
      "+--------------+----+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_results.select('Names', 'Age', 'prediction', 'probability').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
